{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d713f-e307-4c03-b411-3e37b39ea9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Audio, display, clear_output\n",
    "\n",
    "import librosa\n",
    "from birdnetlib import Recording\n",
    "from birdnetlib.analyzer import Analyzer\n",
    "from mosqito import sq_metrics\n",
    "from noisereduce import reduce_noise\n",
    "import pyloudnorm as pyln\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "raw_dir = Path('../audio/data/raw/').resolve()\n",
    "examples = [path for path in raw_dir.glob('*.mp3')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595c9240-305b-444f-9e00-818d9338ecdf",
   "metadata": {},
   "source": [
    "# Presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35b62f-3e86-4055-9e3b-bb6cd65c3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def presence_score(x, window):\n",
    "    # Ensure x is a list of floats of length `window_size`, padding with zero\n",
    "    x = list(x)[:window]\n",
    "    x = [float(xi) for xi in x]\n",
    "    x = x + [0]*(window - len(x))\n",
    "    \n",
    "    if x[0] == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return sum([xi / (i+1) for i, xi in enumerate(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafeebc8-9c65-42ac-9199-70ccd0fbbe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def presence_window(analyzer, filepath, scientific_name=None, window_size=4):\n",
    "    seconds_per_segment = 3\n",
    "\n",
    "    recording = Recording(analyzer, filepath, return_all_detections=True)\n",
    "    recording.analyze()\n",
    "    detections = pd.DataFrame(recording.detections)\n",
    "\n",
    "    if scientific_name is None:\n",
    "        counts = detections['scientific_name'].value_counts()\n",
    "        target = counts.index[0]\n",
    "    else:\n",
    "        target = scientific_name\n",
    "\n",
    "    df = detections[['start_time', 'scientific_name']].copy()\n",
    "    df['segment'] = df['start_time'].div(seconds_per_segment).astype(int)\n",
    "    df['target'] = df['scientific_name'] == target\n",
    "    \n",
    "    good_segments = df.groupby('segment')['target'].apply(lambda x: np.all(x))\n",
    "    good_segments = good_segments.reindex(range(max(good_segments.index) + 1)).fillna(False)\n",
    "    \n",
    "    rolling_good_count = (\n",
    "        good_segments\n",
    "        .rolling(window=window_size, min_periods=1)\n",
    "        .apply(lambda x: presence_score(x, window=window_size))\n",
    "    )\n",
    "    idx = rolling_good_count.idxmax()\n",
    "    \n",
    "    result = {\n",
    "        \"filepath\": filepath,\n",
    "        \"start\": idx,\n",
    "        \"end\": idx + window_size*seconds_per_segment,\n",
    "        \"target\": target,\n",
    "        \"presence\": rolling_good_count.loc[idx],\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "analyzer = Analyzer()\n",
    "\n",
    "recordings = pd.DataFrame([presence_window(analyzer, ex) for ex in examples])  \n",
    "\n",
    "clear_output(wait=True)\n",
    "\n",
    "recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8377ea40-5b8b-4a2a-b8ce-099f5cc2508d",
   "metadata": {},
   "source": [
    "# Noise reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3412f638-f06c-4528-b261-72b64d8855bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings['noise_rmsd'] = 999.9\n",
    "for idx, row in recordings.iterrows():\n",
    "    data, rate = librosa.load(row['filepath'], sr=None)   \n",
    "    clip = data[row['start']*rate:row['end']*rate]\n",
    "    nr_clip = reduce_noise(clip, rate, stationary=False)\n",
    "    recordings.loc[idx, 'noise_rmsd'] = np.sqrt(np.mean((clip - nr_clip)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766f5d7c-0510-49d2-86ed-fa4d45f5a722",
   "metadata": {},
   "source": [
    "# Mosquito feaures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ac62e-f2c7-4b46-9a7f-a9a65fb6fd52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recordings['zwst'] = 999.9\n",
    "for idx, row in recordings.iterrows():\n",
    "    data, rate = librosa.load(row['filepath'], sr=48000)  # Set sr to avoid warning about upsampling    \n",
    "    start, end = row['start'] * rate, row['end'] * rate\n",
    "    recordings.loc[idx, 'zwst'], _, _ = sq_metrics.loudness_zwst(data[start:end], rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1426f292-fa86-4ecf-af28-c9f9d5ef555e",
   "metadata": {},
   "source": [
    "# Librosa features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d87ff9-bc16-476b-905e-e4cbc19869ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noise_features(data, rate):\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(data))\n",
    "    spectral_flatness = np.mean(librosa.feature.spectral_flatness(y=data))\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=data, sr=rate))\n",
    "    \n",
    "    S = np.abs(librosa.stft(data))\n",
    "    freqs = librosa.fft_frequencies(sr=rate)\n",
    "    low_freq_ratio = np.sum(S[freqs < 300]) / np.sum(S)  # Energy below 300 Hz\n",
    "    \n",
    "    rms = librosa.feature.rms(y=data).flatten()\n",
    "    rms_sd = np.std(rms)\n",
    "    rms_mean = np.mean(rms)\n",
    "    \n",
    "    rolling_mean = pd.Series(rms).rolling(window=10).mean().dropna()\n",
    "    floor = rolling_mean.min()\n",
    "    peak = rolling_mean.quantile(0.95)\n",
    "    floor_to_peak = floor / peak if peak > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"zcr\": zcr,\n",
    "        \"spectral_flatness\": spectral_flatness,\n",
    "        \"spectral_centroid\": spectral_centroid,\n",
    "        \"low_freq_ratio\": low_freq_ratio,\n",
    "        \"rms_mean\": rms_mean,\n",
    "        \"rms_sd\": rms_sd,\n",
    "        \"rms_cv\": rms_sd / rms_mean,\n",
    "        \"floor_to_peak\": floor_to_peak\n",
    "    }\n",
    "\n",
    "\n",
    "feature_names = [\"zcr\", \"spectral_flatness\", \"spectral_centroid\", \"low_freq_ratio\", \"rms_mean\", \"rms_sd\", \"rms_cv\", \"floor_to_peak\"]\n",
    "for v in feature_names:\n",
    "    recordings[v] = -9.9\n",
    "    \n",
    "for idx, row in recordings.iterrows():\n",
    "    data, rate = librosa.load(row['filepath'])\n",
    "    start, end = row['start']*rate, row['end']*rate\n",
    "    features = extract_noise_features(data[start:end], rate)\n",
    "    for v in feature_names:\n",
    "        recordings.loc[idx, v] = features[v]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bcd124-0a72-4623-ae99-b96ece1963a7",
   "metadata": {},
   "source": [
    "# Feature comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1783b7-f321-4f53-ae66-3f5c52b58d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4199af7d-013e-4c6f-82d7-9d41f162fc58",
   "metadata": {},
   "source": [
    "Choose any feature to sample audio with low versus high values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1c6d4-ca45-40e7-aa3c-f6b5b58b8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_compare(df, col, n=3, quantile=.2, start_col='start', end_col='end'):\n",
    "    df = df.copy().sort_values(col)\n",
    "    \n",
    "    base_idx = int(len(df) * quantile)\n",
    "    ii = list(range(base_idx, base_idx + n))\n",
    "    ii = ii + [len(df) - i - 1 for i in ii]\n",
    "    \n",
    "    for i in ii:\n",
    "        row = df.iloc[i]\n",
    "        print(col, row[col])\n",
    "        data, rate = librosa.load(row['filepath'])\n",
    "        start = row[start_col] * rate\n",
    "        end = row[end_col] * rate\n",
    "        display(Audio(data[start:end], rate=rate))\n",
    "\n",
    "\n",
    "audio_compare(recordings, \"floor_to_peak\", quantile=.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c56a429-d553-48c3-96cb-abd833e4a527",
   "metadata": {},
   "source": [
    "# Onset detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb083e75-63fb-43d3-afd5-4849e120977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_onset(filepath, start_sec, delta=.25):\n",
    "    data, rate = librosa.load(filepath)\n",
    "\n",
    "    # \"Offset\" because times are relative to clip, not full audio\n",
    "    onsets = librosa.onset.onset_detect(y=data, sr=rate, backtrack=True, units='time', delta=delta)\n",
    "    \n",
    "    onsets = np.array(onsets)\n",
    "    onsets = onsets[onsets < start_sec + 3]\n",
    "    onsets = onsets[onsets > start_sec - 1]\n",
    "    \n",
    "    if not len(onsets):\n",
    "        return start_sec\n",
    "    else:\n",
    "        closest_idx = np.argmin(np.abs(start_sec - onsets))\n",
    "        return onsets[closest_idx]\n",
    "\n",
    "\n",
    "recordings['onset'] = -9.9\n",
    "for idx, row in recordings.iterrows():\n",
    "    recordings.loc[idx, 'onset'] = find_onset(row['filepath'], row['start'], delta=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46693df5-3d5b-47c7-82c2-3dcbe71f06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(recordings['onset'] == recordings['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c764f082-5347-4a01-8da8-0a2c73317701",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = recordings['onset'] - recordings['start']\n",
    "diff.plot(kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0485b9-051f-4b57-a086-7fad8febde83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.random.choice(recordings.index, 5):\n",
    "    row = recordings.loc[idx]\n",
    "    data, rate = librosa.load(row['filepath'])\n",
    "    start = int(row['onset'] * rate)\n",
    "    end = int((row['onset'] + 9) * rate)\n",
    "    print(row['onset'] - row['start'])\n",
    "    display(Audio(data[start:end], rate=rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5a012-eb1d-426a-a624-04a9078f21d2",
   "metadata": {},
   "source": [
    "# Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b3cb25-5261-4f0f-9b9a-b5400e5a663a",
   "metadata": {},
   "source": [
    "Find the quietest and the loudest recording to compare. This works poorly without filtering out noisy recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1618f2c-c176-4234-a522-2291e5dca446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sec(filepath, start=None, end=None):\n",
    "    data, rate = librosa.load(filepath)\n",
    "    if start is not None:\n",
    "        start = int(start * rate)\n",
    "    if end is not None:\n",
    "        end = int(end * rate)\n",
    "    return data[start:end], rate\n",
    "    \n",
    "\n",
    "def get_loudness(filepath, start, end):\n",
    "    clip, rate = load_sec(filepath, start, end)\n",
    "    meter = pyln.Meter(rate)\n",
    "    loudness = meter.integrated_loudness(clip)\n",
    "    return loudness\n",
    "    \n",
    "\n",
    "loud = pd.Series([get_loudness(row['filepath'], row['onset'], row['onset'] + 9) for _, row in recordings.iterrows()])\n",
    "mn = loud.argmin()\n",
    "mx = loud.argmax()\n",
    "\n",
    "row = recordings.iloc[mn]\n",
    "data_quiet, rate_quiet = load_sec(row['filepath'], row['onset'], row['onset'] + 9)\n",
    "print(\"db =\", loud.iloc[mn])\n",
    "display(Audio(data_quiet, rate=rate_quiet))\n",
    "\n",
    "row = recordings.iloc[mx]\n",
    "data_loud, rate_loud = load_sec(row['filepath'], row['onset'], row['onset'] + 9)\n",
    "print(\"db =\", loud.iloc[mx])\n",
    "display(Audio(data_loud, rate=rate_loud))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e3c0c-9634-491c-b008-9cbb50cb9aed",
   "metadata": {},
   "source": [
    "Normalize the volumes and measuring the amount of clipping. Suggested to keep below .0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb9a50-ed9f-4d17-8105-35a62bbf0ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_loudness(data, rate, db=-20, threshold = 1.0):\n",
    "    meter = pyln.Meter(rate)\n",
    "    loudness = meter.integrated_loudness(data)\n",
    "    \n",
    "    new_data = pyln.normalize.loudness(data, loudness, db)\n",
    "    new_loudness = meter.integrated_loudness(new_data)\n",
    "\n",
    "    clipping_prop = np.mean(np.abs(new_data) > threshold)\n",
    "    \n",
    "    return new_data, rate, loudness, new_loudness, clipping_prop\n",
    "\n",
    "\n",
    "data, rate, loudness, new_loudness, clipping = normalize_loudness(data_quiet, rate_quiet)\n",
    "print(\"db\", loudness, \"to\", new_loudness, \"and clipping =\", clipping)\n",
    "display(Audio(data, rate=rate))\n",
    "\n",
    "data, rate, loudness, new_loudness, clipping  = normalize_loudness(data_loud, rate_loud)\n",
    "print(\"db\", loudness, \"to\", new_loudness, \"and clipping =\", clipping)\n",
    "display(Audio(data, rate=rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
